{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw9I-x4Vq4oY"
      },
      "outputs": [],
      "source": [
        "# LUCKNOW EV CHARGING DATASET PIPELINE\n",
        "### Notebook 1A + Notebook 1B + Notebook 2 Combined\n",
        "'''\n",
        "This notebook constructs the *complete dataset* for EV charging infrastructure optimization in Lucknow.\n",
        "\n",
        "---\n",
        "\n",
        "## CONTENTS\n",
        "1. **Notebook 1A — Spatial Data**\n",
        "   - Road network (OSMnx)\n",
        "   - POIs\n",
        "   - Building footprints\n",
        "   - 500m grid candidate sites\n",
        "\n",
        "2. **Notebook 1B — Synthetic Temporal Demand**\n",
        "   - Zone creation (commercial / residential / peripheral)\n",
        "   - Transfer-learning arrival curves (from UrbanEV/Shenzhen)\n",
        "   - Per-cell λ_i(t) for low/base/high scenarios\n",
        "\n",
        "3. **Notebook 2 — Composite Spatial Demand Modeling**\n",
        "   - POI density\n",
        "   - Building-area density\n",
        "   - Normalized weights\n",
        "   - demand_score\n",
        "   - Maps + histograms\n",
        "\n",
        "---\n",
        "\n",
        "Outputs saved in `output/`:\n",
        "- lucknow_graph.graphml\n",
        "- pois_lucknow.geojson\n",
        "- buildings_lucknow.geojson\n",
        "- candidate_grid_500m.geojson\n",
        "- candidate_sites_with_weights.geojson\n",
        "- zone_arrival_profiles.png\n",
        "- scenario_arrival_profiles.png\n",
        "- synthetic_temporal_demand_per_cell.npz\n",
        "- synthetic_temporal_demand_summary.csv\n",
        "- demand_histogram.png\n",
        "- candidate_demand_map.png\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install osmnx geopy rtree shapely fiona geopandas --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjP-eumLwGUl",
        "outputId": "31d1c97f-5209-4517-d207-e527740d01cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Point\n",
        "from sklearn.cluster import KMeans\n",
        "import osmnx as ox\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "OUT = \"output\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "print(\"Output directory:\", OUT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-U5gNSarEl_",
        "outputId": "674db9aa-0765-4eee-a3d3-c59534eba8bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "place = \"Lucknow, Uttar Pradesh, India\"\n",
        "\n",
        "G = ox.graph_from_place(place, network_type=\"drive\")\n",
        "G = ox.project_graph(G)\n",
        "ox.save_graphml(G, f\"{OUT}/lucknow_graph.graphml\")\n",
        "print(\"Saved graph.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIUBzFE9wQHp",
        "outputId": "d2843c3c-cc7b-4fa5-8168-5a63009c4a0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = {\"amenity\": True, \"shop\": True, \"office\": True}\n",
        "pois = ox.features_from_place(place, tags=tags)   # NEW correct function\n",
        "pois = pois.to_crs(G.graph[\"crs\"])\n",
        "pois = pois[pois.geometry.type.isin([\"Point\",\"Polygon\",\"MultiPolygon\"])]\n",
        "pois.to_file(f\"{OUT}/pois_lucknow.geojson\", driver=\"GeoJSON\")\n",
        "print(\"Saved POIs:\", len(pois))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0CmYCvXwo_F",
        "outputId": "68f0ab15-27df-40b7-c4e6-097b39e359f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved POIs: 1757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try modern OSMnx method\n",
        "try:\n",
        "    buildings = ox.features_from_place(place, tags={\"building\": True})\n",
        "except Exception as e:\n",
        "    print(\"features_from_place failed. Error:\", e)\n",
        "    buildings = None\n",
        "\n",
        "# If buildings still None, fallback to geocode + mask from entire place\n",
        "if buildings is None or len(buildings) == 0:\n",
        "    print(\"Fallback: Using geometries_from_bbox instead (broad but safe).\")\n",
        "    bounds = ox.geocode_to_gdf(place).to_crs(G.graph[\"crs\"]).geometry.iloc[0].bounds\n",
        "    north, south, east, west = bounds[3], bounds[1], bounds[2], bounds[0]\n",
        "    buildings = ox.features_from_bbox(north, south, east, west, tags={\"building\": True})\n",
        "    buildings = buildings.to_crs(G.graph[\"crs\"])\n",
        "\n",
        "# Keep only valid polygon geometries\n",
        "buildings = buildings[buildings.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
        "\n",
        "# Save\n",
        "buildings.to_file(f\"{OUT}/buildings_lucknow.geojson\", driver=\"GeoJSON\")\n",
        "print(\"Saved buildings:\", len(buildings))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrWShMOkzGDG",
        "outputId": "39c84e26-4631-4cbc-c3bd-fcbb5eb0c7bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved buildings: 8089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boundary_poly = ox.geocode_to_gdf(place).to_crs(G.graph[\"crs\"]).geometry.iloc[0]\n",
        "minx, miny, maxx, maxy = boundary_poly.bounds\n",
        "\n",
        "xs = np.arange(minx, maxx, 500)\n",
        "ys = np.arange(miny, maxy, 500)\n",
        "\n",
        "points = [Point(x, y) for x in xs for y in ys]\n",
        "candidates = gpd.GeoDataFrame(geometry=points, crs=G.graph[\"crs\"])\n",
        "candidates = candidates[candidates.intersects(boundary_poly)]\n",
        "\n",
        "candidates.to_file(f\"{OUT}/candidate_grid_500m.geojson\", driver=\"GeoJSON\")\n",
        "print(\"Saved candidate grid:\", len(candidates))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CriZF4cM01re",
        "outputId": "157aae73-ecc4-4431-c992-41d4356040cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved candidate grid: 10100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cand = gpd.read_file(f\"{OUT}/candidate_grid_500m.geojson\")\n",
        "n_cells = len(cand)\n",
        "cand = cand.reset_index().rename(columns={\"index\":\"id\"})\n"
      ],
      "metadata": {
        "id": "t0HfbMcM03Vg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords = np.vstack([cand.geometry.x, cand.geometry.y]).T\n",
        "kmeans = KMeans(n_clusters=3, random_state=42).fit(coords)\n",
        "cand[\"zone_id\"] = kmeans.labels_\n",
        "zone_map = {0:\"Z1_commercial\", 1:\"Z2_residential\", 2:\"Z3_peripheral\"}\n",
        "cand[\"zone\"] = cand[\"zone_id\"].map(zone_map)\n"
      ],
      "metadata": {
        "id": "jB6uWRex056g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hours = np.arange(24)\n",
        "\n",
        "def norm(arr):\n",
        "    arr = np.array(arr, float)\n",
        "    arr[arr<0]=0\n",
        "    return arr / (arr.sum()+1e-9)\n",
        "\n",
        "lambda_Z1 = norm([0.2,0.2,0.2,0.3,0.4,0.7,1.0,1.1,1.0,0.9,0.7,0.6,\n",
        "                  0.5,0.5,0.6,0.8,1.0,1.1,0.9,0.7,0.5,0.4,0.3,0.2])\n",
        "\n",
        "lambda_Z2 = norm([0.1,0.1,0.1,0.1,0.2,0.3,0.4,0.6,0.7,0.9,1.0,1.1,\n",
        "                  1.1,1.0,0.9,0.8,0.7,0.6,0.4,0.3,0.2,0.1,0.1,0.1])\n",
        "\n",
        "lambda_Z3 = norm([0.1]*6 + [0.2]*3 + [0.3]*9 + [0.2]*3 + [0.1]*3)\n",
        "\n",
        "profiles = {\"Z1_commercial\":lambda_Z1, \"Z2_residential\":lambda_Z2, \"Z3_peripheral\":lambda_Z3}\n"
      ],
      "metadata": {
        "id": "uzsp76OA079U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(hours, lambda_Z1, label=\"Z1 commercial\")\n",
        "plt.plot(hours, lambda_Z2, label=\"Z2 residential\")\n",
        "plt.plot(hours, lambda_Z3, label=\"Z3 peripheral\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Normalized Arrival Intensity\")\n",
        "plt.title(\"Stylized Arrival Curves (Transferred)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(f\"{OUT}/zone_arrival_profiles.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "obxMVBd7091L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demand proxy: uniform for now, replaced later by demand_score from Notebook 2\n",
        "cand[\"s_i\"] = 1.0\n",
        "\n",
        "rho_vals = {\"low\":0.3, \"base\":1.0, \"high\":2.0}\n",
        "lambda_cells = {k: np.zeros((n_cells,24)) for k in rho_vals}\n",
        "\n",
        "for idx,row in cand.iterrows():\n",
        "    p = profiles[row.zone]\n",
        "    for scen,rho in rho_vals.items():\n",
        "        lambda_cells[scen][idx,:] = rho * row.s_i * p\n",
        "\n",
        "np.savez_compressed(\n",
        "    f\"{OUT}/synthetic_temporal_demand_per_cell.npz\",\n",
        "    hours=hours, **{f\"lambda_{k}\":v for k,v in lambda_cells.items()}\n",
        ")\n",
        "\n",
        "print(\"Saved temporal demand arrays.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgbMdKVV1C26",
        "outputId": "85499f6a-33ea-4bb8-e9b8-9a5a02972853"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved temporal demand arrays.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for scen, arr in lambda_cells.items():\n",
        "    city_profile = arr.sum(axis=0)\n",
        "    plt.plot(hours, city_profile, label=scen)\n",
        "plt.legend()\n",
        "plt.title(\"Scenario-based Synthetic Arrival Profiles\")\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Total Expected Arrivals\")\n",
        "plt.grid(True)\n",
        "plt.savefig(f\"{OUT}/scenario_arrival_profiles.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "io1XoXB-1KHz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pois = gpd.read_file(f\"{OUT}/pois_lucknow.geojson\")\n",
        "buildings = gpd.read_file(f\"{OUT}/buildings_lucknow.geojson\")\n",
        "\n",
        "# CRS alignment\n",
        "cand = cand.to_crs(pois.crs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRDgAw9Z1LMc",
        "outputId": "cd48ca98-2128-4f2c-e6c4-a6d89e0ebcc4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyogrio/raw.py:198: RuntimeWarning: Several features with id = 212882546 have been found. Altering it to be unique. This warning will not be emitted anymore for this layer\n",
            "  return ogr_read(\n",
            "/usr/local/lib/python3.12/dist-packages/pyogrio/raw.py:198: RuntimeWarning: Several features with id = 101225610 have been found. Altering it to be unique. This warning will not be emitted anymore for this layer\n",
            "  return ogr_read(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cand[\"poi_count\"] = 0\n",
        "sidx = pois.sindex\n",
        "\n",
        "for i,row in cand.iterrows():\n",
        "    buf = row.geometry.buffer(300)\n",
        "    possible = list(sidx.intersection(buf.bounds))\n",
        "    cand.loc[i, \"poi_count\"] = pois.iloc[possible].intersects(buf).sum()\n"
      ],
      "metadata": {
        "id": "I_aBBgKg1bL1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure everything is in a metric CRS\n",
        "cand = cand.to_crs(epsg=3857)\n",
        "buildings = buildings.to_crs(epsg=3857)\n",
        "\n",
        "# Clean and compute building area\n",
        "cand[\"bldg_area\"] = 0.0\n",
        "b_sidx = buildings.sindex\n",
        "\n",
        "for i, row in cand.iterrows():\n",
        "    buf = row.geometry.buffer(300)   # 300m radius\n",
        "    possible = list(b_sidx.intersection(buf.bounds))\n",
        "    if possible:\n",
        "        subset = buildings.iloc[possible]\n",
        "        subset = subset[subset.intersects(buf)]\n",
        "        area = subset.area.sum()  # NOW correctly in square meters\n",
        "    else:\n",
        "        area = 0\n",
        "    cand.loc[i, \"bldg_area\"] = area\n"
      ],
      "metadata": {
        "id": "7PSy_SRy10o0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mm(s):\n",
        "    return (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
        "\n",
        "cand[\"P_n\"] = mm(cand[\"poi_count\"])\n",
        "cand[\"B_n\"] = mm(cand[\"bldg_area\"])\n",
        "\n",
        "# weights\n",
        "wB, wP = 1.0, 2.0\n",
        "\n",
        "cand[\"demand_score\"] = wB*cand[\"B_n\"] + wP*cand[\"P_n\"]\n",
        "\n",
        "cand.to_file(f\"{OUT}/candidate_sites_with_weights.geojson\", driver=\"GeoJSON\")\n",
        "print(\"Saved weighted candidate file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQUk_BGe29sV",
        "outputId": "f9eaf964-11f4-44c7-8c46-b48f230435eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved weighted candidate file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(cand[\"demand_score\"], bins=30)\n",
        "plt.title(\"Distribution of demand_score\")\n",
        "plt.xlabel(\"demand_score\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.grid(True)\n",
        "plt.savefig(f\"{OUT}/demand_histogram.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "pjgsy-Rp3AU5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "cand.plot(column=\"demand_score\", cmap=\"viridis\", markersize=15, legend=True)\n",
        "plt.title(\"Candidate Locations Colored by demand_score\")\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(f\"{OUT}/candidate_demand_map.png\", dpi=200, bbox_inches=\"tight\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BdSZMLI63CUe",
        "outputId": "aface825-f30a-489d-d976-776ec86c7154"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}